{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Error Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split your data into train (60%), cross validation (30%) and test (10%).\n",
    "2. Compute the error function (MSE) value for your training, cross validation and testing data.\n",
    "    - if very high training error then high bias (underfitted)\n",
    "    - if very low training error but high cross validation error then high variance (overfitted)\n",
    "3. Try changing the degree of the polynomial and find the optimal degree (if it is a linear regression model).\n",
    "4. Try changing the regularization coefficient of the learning algorithm of that model.\n",
    "5. Try getting more data in which the model is poor at.\n",
    "5. Train many models with different degrees and reg.coeffs then choose the model that has lowest cross validation error and test its accuracy with the test data.\n",
    "6. In neural networks, simple model works well when compared to complex model. Complex model overfits the training data. Try having fewer neurons, optimal regularization coefficent, around 100-1000 epochs.\n",
    "7. In neural networks, apply regularization methods such as dropout or L2 regularization to prevent the model from becoming too complex.\n",
    "\n",
    "- Note: Plot the graph of prediction, error for different degree and reg.coeff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transfer Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download neural network parameters pretrained on a large dataset with same input type (image, audio, text) as your application from the internet. (trained on a pretty large dataset like 1 million sample)\n",
    "2. Further train (fine tune) the network on your own data. (when you have a fewer dataset like 1000 sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adding data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of adding more data of everything: Like \"Honeypot\" project. Add more data of the type (in which the model is poor at) where error analysis has indicated it might help.\n",
    "\n",
    "Beyond getting brand new training example (x, y), another technique: Data augmentation.\n",
    "\n",
    "1. Augmentation: modifying an existing training example to create a new training example. Data augmentation by introducing distortions, adding noise.\n",
    "2. Synthesis: using artificial data inputs to create a new training example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Full cycle of a machine learning project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scope project (Define project)\n",
    "2. Collect data (Define and collect data)\n",
    "3. Train model (Training, error analysis & iterative improvement i.e: go back to step 2)\n",
    "4. Deploy in production (Deploy, monitor and maintain system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Precision & Recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with classification of rare data. A worse model can have a greater accuracy because of imperfect ratio of the positive and negative data. So to find the accuracy of such a model we compute the precision and recall.\n",
    "\n",
    "- Precision = True positives / #predicted positives\n",
    "- Recall = True positives / #actual positives\n",
    "\n",
    "Terminologies\n",
    "\n",
    "- True positives (Actual positive predicted as positive)\n",
    "- False positives (Actual negative predicted as positive)\n",
    "- True negatives (Actual negative predicted as negative)\n",
    "- Fasle negatives (Actual positive predicted as negative)\n",
    "\n",
    "Sometimes there would be a tradeoff between the Precision and Recall value. So to find the best out of them, we compute F1 value/ratio.\n",
    "- F1 value = 1 / ((1/2) * ((1/P) + (1/R))) = 2 * PR/(P+R), i.e: harmonic mean of P and R\n",
    "\n",
    "P and R both ranges from 0 to 1. And the F1 value will always be approx.equal to MIN(P, R). P - Precision, R - Recall"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
